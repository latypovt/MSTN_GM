{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import json\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.multitest as smm\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "sns.set(font='Roboto', style='darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = json.loads(open('utils/lut_dict.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feature_names.keys():\n",
    "    if 'area' in feature:\n",
    "        feature_names[feature] = feature_names[feature] + \" A\"\n",
    "    elif 'thickness' in feature:\n",
    "        feature_names[feature] = feature_names[feature] + \" T\"\n",
    "    else:\n",
    "        feature_names[feature] = feature_names[feature]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORGANIZE DATA\n",
    "#############################################################\n",
    "\n",
    "# create dataframes\n",
    "important_features = pd.read_csv(\"out/important_features.csv\")\n",
    "ml_dataframe = pd.read_csv(\"stats/ml_dataframe.csv\")\n",
    "print(ml_dataframe.shape)\n",
    "ml_dataframe = ml_dataframe.dropna(axis=0)\n",
    "print(ml_dataframe.shape)\n",
    "\n",
    "# rename columns \n",
    "important_features = important_features.rename(columns={'feature': 'importance'})\n",
    "important_features = important_features.rename(columns={'Unnamed: 0': 'feature'})\n",
    "\n",
    "# print all important features into a new list\n",
    "important_features_list = important_features['feature'].tolist()\n",
    "\n",
    "# save names of features where importance >=5 to a list called top_features\n",
    "top_features = important_features[important_features['importance'] >= 5]\n",
    "top_features = top_features['feature'].tolist()\n",
    "\n",
    "# make separate dataframe for top features' importance \n",
    "top_features_importance = important_features[important_features['importance'] >= 5]\n",
    "\n",
    "# reading LUT\n",
    "region_names = np.array(list([feature_names[feature] for feature in important_features['feature']]))\n",
    "\n",
    "# add label column\n",
    "important_features['feature type'] = np.where(important_features['feature'].str.contains('thickness'), \"thickness\", \n",
    "                                       np.where(important_features['feature'].str.contains('area'), \"area\", \"volume\"))\n",
    "important_features['feature'] = region_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate histogram of all features\n",
    "# with plt.xkcd():\n",
    "#     ax1 = sns.catplot(data=important_features, kind=\"bar\", x=\"importance\", y=\"feature\", height=15, aspect=2, hue=\"feature type\", dodge=False, palette=['#5Ef2A8', '#6E8CE3', '#FF9F21'])\n",
    "#     plt.xticks([0,1,2,3,4,5,6,7,8,9,10])    \n",
    "#     plt.title(\"Feature Importance\", fontsize=40)\n",
    "#     plt.xlabel(\"Importance\", fontsize=30)\n",
    "#     plt.ylabel(\"Feature\", fontsize=30)\n",
    "#     # plt.savefig('out/important_features.png', dpi=300, bbox_inches='tight')\n",
    "#     plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE WEIGHTS\n",
    "#############################################################\n",
    "\n",
    "# make a graph to visualize the feature weights data in outs folder ([fold]_feature_weights.csv)\n",
    "#load df from all folds and merge into one dataframe\n",
    "\n",
    "#create new dataframe for each fold file\n",
    "\n",
    "dataframes = []  # List to store the dataframes\n",
    "\n",
    "for i in range(0,10):\n",
    "    filename=('out/{}_feature_weights.csv'.format(i))\n",
    "     # Generate the filename\n",
    "    df = pd.read_csv(filename)  # Read the CSV file into a dataframe\n",
    "    dataframes.append(df)\n",
    "\n",
    "# rename first column of each dataframe to fold #\n",
    "for i in range(0,10):\n",
    "    dataframes[i] = dataframes[i].rename(columns={'Unnamed: 0': 'fold #'})\n",
    "    dataframes[i]['fold #'] = i\n",
    "\n",
    "# merge all 10 dataframes within dataframes list into a single dataframe\n",
    "all_weights = pd.concat(dataframes)\n",
    "all_weights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt\n",
    "all_weights = pd.melt(all_weights, id_vars=['fold #'], var_name='feature', value_name='weight')\n",
    "print(all_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make top_weights dataframe where feature is in top_features list\n",
    "top_weights = all_weights[all_weights['feature'].isin(top_features)]\n",
    "\n",
    "# abbreviate names\n",
    "region_names = np.array(list([feature_names[feature] for feature in top_weights['feature']]))\n",
    "top_weights['feature'] = region_names\n",
    "\n",
    "#do same for top_features_importance\n",
    "region_names = np.array(list([feature_names[feature] for feature in top_features_importance['feature']]))\n",
    "top_features_importance['feature'] = region_names\n",
    "\n",
    "# add 'importance' column to top_weights datafram where the importance is the importance of that feature based on 'importance' from top_features_importance\n",
    "top_weights['importance'] = top_weights['feature'].map(top_features_importance.set_index('feature')['importance'])\n",
    "\n",
    "\n",
    "# abs value\n",
    "top_weights['weight'] = top_weights['weight'].abs()\n",
    "top_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "print(top_features)\n",
    "for i, _ in  enumerate(top_features):\n",
    "    means.append((top_weights.groupby('feature').max().sort_values('weight', ascending=False)['weight'][i]))\n",
    "\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network colours for bar plot\n",
    "palette_dict = {'R VM V': '#c5ed85', 'L PerCaS A': '#ff8e52', 'R PosCG A': '#5edb69', 'R SupFS A': '#ff8e52',\n",
    "                'L RG T': '#6d8ded', 'R L-Sg V': '#ff6376', 'L TOS A': '#ff8e52', 'R HG A': '#5edb69',\n",
    "                'L InfCrInS T': '#ff8e52', 'L PuI V': '#ff6376', 'R CA3 Body V': '#6d8ded', 'L VPL V': '#5edb69',\n",
    "                'R FuG A': '#6d8ded', 'R MDm V': '#a773de','L PerCaS T': '#ff8e52', 'R InfCrInS T': '#ff8e52', \n",
    "                'R Cun T': '#ff6376'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "# boxplot\n",
    "ax=sns.boxplot(data=top_weights, x=\"feature\", y=\"weight\", palette=palette_dict, order=top_weights.groupby('feature').mean()\n",
    "               .sort_values('weight', ascending=False).index)\n",
    "\n",
    "# For gray outline:: boxprops={'edgecolor':'gray'}, flierprops={\"markerfacecolor\": \"gray\", \"markeredgecolor\":\"gray\"}, medianprops={\"color\": \"gray\"}, whiskerprops={\"color\": \"gray\"}, capprops={\"color\": \"gray\"},\n",
    "\n",
    "# add stripplot\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.stripplot(data=top_weights, x=\"feature\", y=\"weight\", size=4, color='#5E5E5E', order=top_weights.groupby('feature')\n",
    "              .mean().sort_values('weight', ascending=False).index)\n",
    "\n",
    "# save axis labels and means in separate list\n",
    "xlabels = top_weights.groupby('feature').mean().sort_values('weight', ascending=False)\n",
    "xlabels_list = xlabels.index.tolist()\n",
    "xlabels_means = xlabels['weight'].tolist()\n",
    "\n",
    "xlabels_importance = [10, 5, 6, 7, 6, 9, 5, 6, 7, 7, 5, 8, 8, 5, 6, 6, 6]\n",
    "\n",
    "plt.xticks(rotation=30,size=18,rotation_mode=\"anchor\", ha=\"right\", ticks=np.arange(0, len(xlabels), 1))\n",
    "plt.yticks(size=18)\n",
    "\n",
    "plt.xlabel('Brain Region', size=24)\n",
    "plt.ylabel('Weight (abs. value)', size=24)\n",
    "\n",
    "# max weight of each feature\n",
    "xlabels_max = top_weights.groupby('feature').max().sort_values('weight', ascending=False)\n",
    "max_weights = []\n",
    "for index, row in xlabels_max.iterrows():\n",
    "    max_weights.append(row['weight'])\n",
    "\n",
    "# fold labels\n",
    "for i,_ in enumerate(max_weights):\n",
    "    plt.text(x=i, y=(max_weights[i]+0.04), s=xlabels_importance[i], color='#5E5E5E', ha=\"center\", fontsize=12)\n",
    "    plt.scatter(x=i, y=(max_weights[i]+0.045), s=300, color='white', zorder=2, edgecolor='#5E5E5E', linewidth=1.5)\n",
    "\n",
    "\n",
    "plt.savefig('out/feature_weights.png', dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-TEST\n",
    "#############################################################\n",
    "\n",
    "# create dataframe with only top features\n",
    "top_features_dataframe = ml_dataframe[top_features]\n",
    "top_features_dataframe['diagnosis'] = ml_dataframe['diagnosis']\n",
    "\n",
    "# calculate mean for each column and put in list\n",
    "means = []\n",
    "for i, _ in enumerate(top_features):\n",
    "    means.append(top_features_dataframe.mean()[top_features[i]])\n",
    "\n",
    "# melt and organize dataframe for top features\n",
    "top_features_dataframe = top_features_dataframe.melt(id_vars=['diagnosis'], var_name='feature', value_name='value').fillna(0)\n",
    "top_features_dataframe['feature'] = [feature_names[feature] for feature in top_features_dataframe['feature']]\n",
    "\n",
    "# # create and melt dataframe for all important features\n",
    "# important_features_dataframe = ml_dataframe[important_features_list]\n",
    "# important_features_dataframe['diagnosis'] = ml_dataframe['diagnosis']\n",
    "# important_features_dataframe = important_features_dataframe.melt(id_vars=['diagnosis'], var_name='feature', value_name='value').fillna(0)\n",
    "# important_features_dataframe['feature'] = [feature_names[feature] for feature in important_features_dataframe['feature']]\n",
    "\n",
    "# set up groups for t-test\n",
    "ms_dataframe = ml_dataframe[ml_dataframe['diagnosis'] == 'MS']\n",
    "ms_tn_dataframe = ml_dataframe[ml_dataframe['diagnosis'] == 'MS-TN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run t-test\n",
    "\n",
    "p_vals = []\n",
    "p_corrected = []\n",
    "stats_vals = []\n",
    "\n",
    "# running t-test on top features\n",
    "for feature in top_features:\n",
    "    input_ms = ms_dataframe[feature]\n",
    "    input_ms_tn = ms_tn_dataframe[feature]\n",
    "    ttest1 = stats.ttest_ind(input_ms, input_ms_tn, equal_var=True, nan_policy=\"omit\", permutations=None, random_state=None, alternative=\"two-sided\", trim=0)\n",
    "    #nan_policy='propagate' when all data there\n",
    "    p_vals.append(ttest1.pvalue)\n",
    "    stats_vals.append(ttest1.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running t-test on all important features\n",
    "for feature in important_features_list:\n",
    "    input_ms = ms_dataframe[feature]\n",
    "    input_ms_tn = ms_tn_dataframe[feature]\n",
    "    ttest1 = stats.ttest_ind(input_ms, input_ms_tn, equal_var=True, nan_policy=\"omit\", permutations=None, random_state=None, alternative=\"two-sided\", trim=0)\n",
    "    p_vals.append(ttest1.pvalue)\n",
    "    stats_vals.append(ttest1.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct p-values for multiple tests\n",
    "\n",
    "rejected_pval, p_corrected = fdrcorrection(p_vals, alpha=0.05, method='indep')\n",
    "\n",
    "# replace rejected p-values with \"NS\"\n",
    "for i in range(len(p_corrected)):\n",
    "    if rejected_pval[i] == False:\n",
    "        p_corrected[i] = 1\n",
    "    else:\n",
    "        p_corrected[i] = p_corrected[i]\n",
    "\n",
    "# save p_corrected of top_features to a csv\n",
    "p_corrected_df = pd.DataFrame(p_corrected, columns=['p_corrected'])\n",
    "p_corrected_df['feature'] = top_features\n",
    "\n",
    "\n",
    "# if saving all important features\n",
    "# p_corrected_df['feature'] = important_features_list\n",
    "# significant_pvals_dict = {}\n",
    "# for pval in p_corrected_df['p_corrected']:\n",
    "#     if pval != 1:\n",
    "#         # add feature name and pval to dictionary\n",
    "#         significant_pvals_dict[p_corrected_df['feature'][p_corrected_df['p_corrected'] == pval].values[0]] = pval\n",
    "#         # sort by descending\n",
    "# significant_pvals_dict = dict(sorted(significant_pvals_dict.items(), key=lambda item: item[1], reverse=False))\n",
    "\n",
    "# print(significant_pvals_dict)\n",
    "# p_corrected_df.to_csv('out/p_corrected_all_significant.csv')\n",
    "\n",
    "\n",
    "# save p_corrected of top features to a csv\n",
    "p_corrected_df.to_csv('out/p_corrected.csv')\n",
    "\n",
    "# copy df into new one  \n",
    "p_corrected_df_values = p_corrected_df.copy()\n",
    "\n",
    "p_corrected_df['p_corrected'] = ['NS' if p_corrected == 1 else '*' if p_corrected > 0.01 \n",
    "                                 else '**' if p_corrected > 0.001 else '***' for p_corrected in p_corrected_df['p_corrected']]\n",
    "p_values_codes = p_corrected_df['p_corrected'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_values_codes)\n",
    "print(important_features_list)\n",
    "pval_dict = {important_features_list[i]: p_values_codes[i] for i in range(len(p_values_codes))}\n",
    "print(pval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make separate dataframes depending on region\n",
    "top_features_dataframe_hippo = top_features_dataframe[top_features_dataframe['feature'].str.contains('CA1|CA2|CA3|CA4|DG|SUB|ERC|Fimbria')]\n",
    "top_features_dataframe_thal = top_features_dataframe[top_features_dataframe['feature'].str.contains('VPL|PuI|VM|VPL|VPM|PuM|VA|VL|PuL|MDm|L-Sg')]\n",
    "top_features_dataframe_v = pd.concat([top_features_dataframe_hippo, top_features_dataframe_thal])\n",
    "\n",
    "top_features_dataframe_t = top_features_dataframe[top_features_dataframe['feature'].str.endswith('T')]\n",
    "top_features_dataframe_a = top_features_dataframe[top_features_dataframe['feature'].str.endswith('A')]\n",
    "\n",
    "# remove the V T and A from the end of the feature names\n",
    "top_features_dataframe_hippo['feature'] = top_features_dataframe_hippo['feature'].str[:-2]\n",
    "top_features_dataframe_thal['feature'] = top_features_dataframe_thal['feature'].str[:-2]\n",
    "top_features_dataframe_v['feature'] = top_features_dataframe_v['feature'].str[:-2]\n",
    "top_features_dataframe_t['feature'] = top_features_dataframe_t['feature'].str[:-2]\n",
    "top_features_dataframe_a['feature'] = top_features_dataframe_a['feature'].str[:-2]\n",
    "\n",
    "# print unique values of top features thal and hippo\n",
    "print(top_features_dataframe_v['feature'].unique())\n",
    "print(top_features_dataframe_t['feature'].unique())\n",
    "print(top_features_dataframe_a['feature'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cortical area\n",
    "# do different subplots for top features separated from the different regions with hipp/thal together\n",
    "\n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.title('Cortical Area', size=40)\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax=sns.boxplot(data=top_features_dataframe_a, x=\"feature\", y=\"value\", hue=\"diagnosis\", palette={\"MS\":\"#FFB453\", \"MS-TN\":\"#70e0ff\"}, boxprops={'edgecolor':'gray'},  flierprops={\"markerfacecolor\": \"gray\", \"markeredgecolor\":\"gray\"}, medianprops={\"color\": \"gray\"}, whiskerprops={\"color\": \"gray\"}, capprops={\"color\": \"gray\"})\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, size=25)\n",
    "plt.setp(ax.get_yticklabels(), size=25)\n",
    "#add scatterplot on top of boxplot\n",
    "ax1=sns.stripplot(data=top_features_dataframe_a, x=\"feature\", y=\"value\", hue=\"diagnosis\", palette={\"MS\":\"#FFB453\", \"MS-TN\":\"#70e0ff\"},\n",
    "                dodge=True, size=5, edgecolor=\"white\", linewidth=1)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\" \", size=30)\n",
    "ax.set_ylabel('Size', size=30)\n",
    "ax.get_legend().remove()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.savefig('out/cortical_area.png', dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cortical thickness\n",
    "plt.figure(figsize=(10, 15))\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.title('Cortical Thickness', size=40)\n",
    "ax=sns.boxplot(data=top_features_dataframe_t, x=\"feature\", y=\"value\", hue=\"diagnosis\", palette={\"MS\":\"#FFB453\", \"MS-TN\":\"#70e0ff\"}, boxprops={'edgecolor':'gray'},  flierprops={\"markerfacecolor\": \"gray\", \"markeredgecolor\":\"gray\"}, medianprops={\"color\": \"gray\"}, whiskerprops={\"color\": \"gray\"}, capprops={\"color\": \"gray\"})\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, size=25)\n",
    "plt.setp(ax.get_yticklabels(), size=25)\n",
    "#add scatterplot on top of boxplot\n",
    "ax1=sns.stripplot(data=top_features_dataframe_t, x=\"feature\", y=\"value\", hue=\"diagnosis\", palette={\"MS\":\"#FFB453\", \"MS-TN\":\"#70e0ff\"},\n",
    "                dodge=True, size=5, edgecolor=\"white\", linewidth=1)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\" \", size=30)\n",
    "ax.set_ylabel('Size', size=30)\n",
    "ax.get_legend().remove()\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.savefig('out/cortical_thickness.png', dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subcor vol\n",
    "plt.figure(figsize=(10, 15))\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.title('Subcortical Volume', size=40)\n",
    "ax=sns.boxplot(data=top_features_dataframe_v, x=\"feature\", y=\"value\", hue=\"diagnosis\", palette={\"MS\":\"#FFB453\", \"MS-TN\":\"#70e0ff\"}, boxprops={'edgecolor':'gray'},  flierprops={\"markerfacecolor\": \"gray\", \"markeredgecolor\":\"gray\"}, medianprops={\"color\": \"gray\"}, whiskerprops={\"color\": \"gray\"}, capprops={\"color\": \"gray\"})\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, size=25)\n",
    "plt.setp(ax.get_yticklabels(), size=25)\n",
    "    #add scatterplot on top of boxplot\n",
    "ax1=sns.stripplot(data=top_features_dataframe_v, x=\"feature\", y=\"value\", hue=\"diagnosis\", palette={\"MS\":\"#FFB453\", \"MS-TN\":\"#70e0ff\"},\n",
    "                    dodge=True, size=5, edgecolor=\"white\", linewidth=1)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\" \", size=30)\n",
    "ax.set_ylabel('Size', size=30)\n",
    "ax.get_legend().remove()\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.savefig('out/subcortical_volume', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run stats on ms_studies demographic data\n",
    "\n",
    "ms_studies = pd.read_csv('stats/MS_studies.csv')\n",
    "print(ms_studies.shape)\n",
    "# drop patients missing featural data\n",
    "ms_studies = ms_studies[ms_studies['id'] != 'tl_0139']\n",
    "ms_studies = ms_studies[ms_studies['id'] != 'tl_0440']\n",
    "ms_studies = ms_studies[ms_studies['id'] != 'ms_19']\n",
    "ms_studies = ms_studies[ms_studies['id'] != 'ms_75']\n",
    "print(ms_studies.shape)\n",
    "\n",
    "# make two dataframes based on ms or ms-tn diagnosis\n",
    "ms_studies_ms = ms_studies[ms_studies['diagnosis'] == 'MS']\n",
    "ms_studies_mstn = ms_studies[ms_studies['diagnosis'] == 'MS-TN']\n",
    "\n",
    "# calculate mean and standard deviation of age and duration of ms from ms and mstn dataframes and print,also sexes\n",
    "print('MS sex:\\n{}'.format(ms_studies_ms['sex'].value_counts()))\n",
    "print(\"MS mean age: {} std: {}\".format(ms_studies_ms['age'].mean(), ms_studies_ms['age'].std()))\n",
    "print(\"MS mean MS duration: {} std: {}\\n\".format(ms_studies_ms['duration_of_ms'].mean(), ms_studies_ms['duration_of_ms'].std()))\n",
    "print('MS-TN sex:\\n{}'.format(ms_studies_mstn['sex'].value_counts()))\n",
    "print(\"MS-TN mean age: {} std: {}\".format(ms_studies_mstn['age'].mean(), ms_studies_mstn['age'].std()))\n",
    "print(\"MS-TN mean MS duration: {} std: {}\".format(ms_studies_mstn['duration_of_ms'].mean(), ms_studies_mstn['duration_of_ms'].std()))\n",
    "print(\"MS-TN mean pain duration: {} std: {}\".format(ms_studies_mstn['duration_of_pain'].mean(), ms_studies_mstn['duration_of_pain'].std()))\n",
    "print(\"MS-TN laterality: {}\".format(ms_studies_mstn['side_of_pain'].value_counts()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
